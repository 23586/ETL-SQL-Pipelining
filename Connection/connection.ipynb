{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c38963d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (3.34.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (2.40.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=24.2.0 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (25.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.73.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb396ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30706a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pyarrow in c:\\users\\wel\\appdata\\roaming\\python\\python312\\site-packages (20.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36df689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c697db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'bronze' created.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get values from environment\n",
    "KEY_FILE = os.getenv(\"KEY_FILE\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "DATASET_ID = \"bronze\"\n",
    "\n",
    "# Setup BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(KEY_FILE)\n",
    "client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
    "\n",
    "# Create bronze dataset\n",
    "dataset_ref = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "dataset.location = \"US\"\n",
    "\n",
    "client.create_dataset(dataset, exists_ok=True)\n",
    "print(\"✅ Dataset 'bronze' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bea1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "CSV_FOLDER = \"Dataset\"  # folder od datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7175fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 'olist_customers_dataset.csv' as table 'olist_customers_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_customers_dataset\n",
      "Uploading 'olist_geolocation_dataset.csv' as table 'olist_geolocation_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_geolocation_dataset\n",
      "Uploading 'olist_orders_dataset.csv' as table 'olist_orders_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_orders_dataset\n",
      "Uploading 'olist_order_items_dataset.csv' as table 'olist_order_items_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_order_items_dataset\n",
      "Uploading 'olist_order_payments_dataset.csv' as table 'olist_order_payments_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_order_payments_dataset\n",
      "Uploading 'olist_order_reviews_dataset.csv' as table 'olist_order_reviews_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_order_reviews_dataset\n",
      "Uploading 'olist_products_dataset.csv' as table 'olist_products_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_products_dataset\n",
      "Uploading 'olist_sellers_dataset.csv' as table 'olist_sellers_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.olist_sellers_dataset\n",
      "Uploading 'product_category_name_translation.csv' as table 'product_category_name_translation'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wel\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded: e-commerce-etl.bronze.product_category_name_translation\n",
      "\n",
      " All raw CSVs uploaded to 'bronze' dataset.\n"
     ]
    }
   ],
   "source": [
    "# === UPLOAD EACH CSV FILE TO BRONZE DATASET ===\n",
    "for file in os.listdir(CSV_FOLDER):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(CSV_FOLDER, file)\n",
    "        table_name = os.path.splitext(file)[0]  # remove .csv extension\n",
    "        table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
    "\n",
    "        print(f\"Uploading '{file}' as table '{table_name}'...\")\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        job = client.load_table_from_dataframe(df, table_ref)\n",
    "        job.result()\n",
    "\n",
    "        print(f\"✅ Uploaded: {table_ref}\")\n",
    "\n",
    "print(\"\\n All raw CSVs uploaded to 'bronze' dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4007a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'silver' created.\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = \"silver\"  # <-- changed from 'bronze' to 'silver'\n",
    "\n",
    "# Setup BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(KEY_FILE)\n",
    "client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
    "\n",
    "# Create silver dataset\n",
    "dataset_ref = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "dataset.location = \"US\"\n",
    "\n",
    "client.create_dataset(dataset, exists_ok=True)\n",
    "print(\"✅ Dataset 'silver' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b9853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
